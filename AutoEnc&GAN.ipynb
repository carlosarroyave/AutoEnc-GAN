{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+1MhrBJeL4bpmCCtxAesA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosarroyave/AutoEnc-GAN/blob/main/AutoEnc%26GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8OO812CLoC2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot original images vs reconstructed images\n",
        "\n",
        "def plot_mnist_autoencoder(x, xpred, cmap='gray', vmin=0, vmax=1):\n",
        "    # Crear una figura y ejes para mostrar las imágenes originales y reconstruidas\n",
        "    fig, ax = plt.subplots(2, x.shape[0], figsize=(20, 5))\n",
        "\n",
        "    # Iterar sobre cada imagen en x y xpred para mostrarlas en subplots correspondientes\n",
        "    for i, class_ in enumerate(range(x.shape[0])):\n",
        "        # Mostrar la imagen original en la fila 0 del subplot\n",
        "        ax[0, i].imshow(x[i], cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "        ax[0, i].set_xticks([])\n",
        "        ax[0, i].set_yticks([])\n",
        "\n",
        "        # Mostrar la imagen reconstruida en la fila 1 del subplot\n",
        "        ax[1, i].imshow(xpred[i], cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "        ax[1, i].set_xticks([])\n",
        "        ax[1, i].set_yticks([])\n",
        "\n",
        "    # Mostrar la figura completa con todas las subplots\n",
        "    plt.show()\n",
        "\n",
        "# Ejemplo de uso de la función\n",
        "# Suponiendo que tienes imágenes en las variables x e xpred\n",
        "# plot_mnist_autoencoder(x, xpred)"
      ],
      "metadata": {
        "id": "V8vzIWygLr91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identificación de por PCA de los resultados de cada capa del modelo utilizado"
      ],
      "metadata": {
        "id": "E9niSahZLuBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_car_PCA(z, y, dim=2):\n",
        "    \"\"\"\n",
        "    Esta función realiza PCA (Análisis de Componentes Principales) en los datos de z y\n",
        "    luego visualiza las proyecciones en un gráfico de scatter para cada capa L en z.\n",
        "\n",
        "    Args:\n",
        "    - z: Objeto que contiene los datos a analizar (debe tener atributos L1, L2, ..., Ln).\n",
        "    - y: Etiquetas de clase para colorear los puntos en el gráfico de dispersión.\n",
        "    - dim: Número de dimensiones para la proyección PCA (por defecto es 2).\n",
        "\n",
        "    \"\"\"\n",
        "    num_L = z.L_n\n",
        "    fig, axes = plt.subplots(1, num_L, figsize=(10*num_L, 10))\n",
        "\n",
        "    for i in range(num_L):\n",
        "        # Obtener los datos de la capa L correspondiente\n",
        "        name_Z = f\"L{i+1}\"\n",
        "        L = getattr(z, name_Z).numpy()\n",
        "        shp = L.shape\n",
        "\n",
        "        # Realizar PCA dependiendo de la forma de los datos en la capa L\n",
        "        if len(shp) == 2:\n",
        "            zpca = PCA(n_components=dim).fit_transform(L.reshape((L.shape[0], L.shape[1])))\n",
        "        elif len(shp) == 3:\n",
        "            zpca = PCA(n_components=dim).fit_transform(L.reshape((L.shape[0], L.shape[1]*L.shape[2])))\n",
        "        elif len(shp) == 4:\n",
        "            zpca = PCA(n_components=dim).fit_transform(L.reshape((L.shape[0], L.shape[1]*L.shape[2]*L.shape[3])))\n",
        "\n",
        "        # Normalizar los datos de PCA entre 0 y 1\n",
        "        zpca = (zpca - zpca.min()) / (zpca.max() - zpca.min())\n",
        "\n",
        "        # Graficar la proyección PCA en un gráfico de scatter\n",
        "        axes[i].scatter(zpca[:, 0], zpca[:, 1], c=y, s=10, cmap=\"tab10\")\n",
        "        axes[i].set_title(f\"L{i+1}\")\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.5)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Ejemplo de uso de la función\n",
        "# plot_car_PCA(z, y, dim=2)"
      ],
      "metadata": {
        "id": "idRYTUnZLwNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataSet utlizado de keras fashion_mnist\n",
        "\n",
        "El dataset esta calsificado en las siguientes clases :  # T-shirt/top, \tTrouser, Pullover,\tDress, \tCoat, Sandal, Shirt, \tSneaker, Bag, Ankle boot"
      ],
      "metadata": {
        "id": "ocqh-8zHL0KJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "g7gdmb4aL1pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "División de los datos en Train, test y valid y se normalizan los datos de 0 a 1"
      ],
      "metadata": {
        "id": "GzFLpC8dL5FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ],
      "metadata": {
        "id": "6SOQC1FfL6Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "id": "VlxUq8T0L8AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0], cmap=\"gray\", vmin=0, vmax=1)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kAuuwPVML911"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se mezclan los datos para garantizar que el modelo no tenga overfitting por el orden de los datos en el entrenamiento."
      ],
      "metadata": {
        "id": "2o1IQzMSMByt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tamano = len(X_train)\n",
        "indice_mezcla = np.random.permutation(tamano)\n",
        "x_tr = X_train[indice_mezcla].reshape([tamano,28,28,1])\n",
        "tamano = len(X_valid)\n",
        "indice_mezcla = np.random.permutation(tamano)\n",
        "x_vl = X_valid[indice_mezcla].reshape([tamano,28,28,1])\n",
        "y_vl = y_valid[indice_mezcla]\n",
        "tamano = len(X_test)\n",
        "indice_mezcla = np.random.permutation(tamano)\n",
        "x_ts = X_test[indice_mezcla].reshape([tamano,28,28,1])"
      ],
      "metadata": {
        "id": "ICVUfSVbMCnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo Autoencoder con Regularizadores\n",
        "\n",
        "Se crea un modelo de autoencoder con una entrada de imagen (28,28) buscando reconstruir la imagen de entrada.\n",
        "\n",
        "Se utliza la siguiente arquitectura para el encoder y decoder.\n",
        "\n",
        "![Arquitectura](ArquitecturaAE.svg)\n",
        "\n",
        "y se utliza la API de los modelos que permite keras para poder seleccionar que tipo de regularización se va a implementar.\n",
        "\n",
        "### Ruido gausiano:\n",
        "El primer regularizador es ruido gausiano en la capa de entrada, generando un grado de aleatoriedad a los datos de entrada y evitar el sobre entrenamiento.\n",
        "\n",
        "### Dropout:\n",
        "Se genera un apagado de las neuronas de forma aleatoria en la capa implementada lo que genera que algunas neuronas no sean las que se especialicen en el entrenamiento y se pueda distribuir el aprendizaje en todas las neuronas de la capa.\n",
        "\n",
        "###  Regularización L1 Lasso:\n",
        "Introduce un termino a la función de costo (L) añadiendo al valor el absoluto de los pesos de la capa, generando que los pesos sean pequeños y no se genere una neurona con mayor importancia que las otras neuronas de la capa.\n",
        "\n",
        "$$\n",
        "L_1(X,\\omega ) =  L(X,\\omega ) + \\lambda \\sum \\left |\\omega_i  \\right |\n",
        "$$\n",
        "\n",
        "###  Regularización L2 Ridge:\n",
        "\n",
        "Introduce un termino a la función de costo (L) añadiendo a su valor la suma de los cuadrados de los parametros ($\\omega$) y se introduce un parametro ($\\lambda$) para ajustar el peso de estos cuadrados de los pesos.\n",
        "\n",
        "$$\n",
        "L_2(X,\\omega ) =  L(X,\\omega ) + \\lambda \\sum \\omega_i^{2}\n",
        "$$"
      ],
      "metadata": {
        "id": "cfl-rV8OMHiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Auto_regul(Model):\n",
        "    \"\"\"\n",
        "    Clase Auto_regul(Model):\n",
        "    Esta clase implementa un modelo de red neuronal con capacidades de regularización\n",
        "    para su uso en tareas de autoencoding u otros problemas de aprendizaje automático.\n",
        "\n",
        "    Parámetros:\n",
        "    - num_n_deep (list): Lista que define el número de neuronas en las capas ocultas del modelo.\n",
        "    - drop_out (list): Lista que define las tasas de dropout para regularización en cada capa.\n",
        "    - **kwargs: Argumentos adicionales que se pueden pasar a la clase Model.\n",
        "\n",
        "    Atributos:\n",
        "    - num_n_deep (list): Número de neuronas en las capas ocultas.\n",
        "    - drop_out (list): Tasas de dropout para regularización.\n",
        "    - L_n (int): Número de capas en el modelo.\n",
        "    - L1-L9 (None): Capas del modelo que se inicializan como None en el constructor.\n",
        "\n",
        "    Métodos:\n",
        "    - __init__: Constructor de la clase para inicializar los atributos.\n",
        "    - build: Método para construir la arquitectura del modelo basado en la forma de entrada.\n",
        "    - call: Método que define la propagación hacia adelante en el modelo y la lógica de regularización.\n",
        "\n",
        "    Uso:\n",
        "    # Crear una instancia de Auto_regul\n",
        "    modelo_auto_regul = Auto_regul(num_n_deep=[64, 64, 64, 1], drop_out=[0.2, 0.2])\n",
        "\n",
        "    # Construir el modelo con la forma de entrada especificada\n",
        "    modelo_auto_regul.build(input_shape=(28, 28, 1))\n",
        "\n",
        "    # Realizar la propagación hacia adelante en el modelo con regularización específica\n",
        "    output = modelo_auto_regul(inputs, regul=2)\n",
        "    Selección del tipo de regularizador:\n",
        "    r = 0 --- Sin gegularizador\n",
        "    r = 1 --- Ruido gausiano\n",
        "    r = 2 --- Dropout Capa entrada y salida Encoder\n",
        "    r = 3 --- Regulairzador L1\n",
        "    r = 4 --- Regulairzador L2\n",
        "\"\"\"\n",
        "    def __init__(self, num_n_deep= [64, 64, 64, 1], drop_out=[0.2, 0.2], **kwargs):\n",
        "        super(Auto_regul, self).__init__()\n",
        "        # Parámetros para la arquitectura del modelo\n",
        "        self.num_n_deep = num_n_deep\n",
        "        self.drop_out   = drop_out\n",
        "        # Número de capas en el modelo\n",
        "        self.L_n= 9\n",
        "        self.L1 = None\n",
        "        self.L2 = None\n",
        "        self.L3 = None\n",
        "        self.L4 = None\n",
        "        self.L5 = None\n",
        "        self.L6 = None\n",
        "        self.L7 = None\n",
        "        self.L8 = None\n",
        "        self.L9 = None\n",
        "\n",
        "    def build(self, input_shape, kernel_size=[3, 3, 3, 3]):\n",
        "\n",
        "        self.kernel_size=kernel_size\n",
        "        self.Pred_Layer0_Noise      = layers.GaussianNoise(0.2)\n",
        "        self.Pred_Layer0_Dropout1    = layers.Dropout(self.drop_out[0])\n",
        "        self.Pred_Layer1_conv1      = layers.Conv2D(filters = self.num_n_deep[0], kernel_size=self.kernel_size[0],  activation=\"relu\")\n",
        "        self.Pred_Layer2_conv2      = layers.Conv2D(filters = self.num_n_deep[1], kernel_size=self.kernel_size[1], activation=\"relu\")\n",
        "        self.Pred_Layer3_flatten    = layers.Flatten()\n",
        "        self.Pred_Layer4_Dense1     = layers.Dense(units=32, activation='relu')\n",
        "        self.Pred_Layer5_Dense2     = layers.Dense(units=(input_shape[1]*input_shape[2]), activation='relu')\n",
        "        self.Pred_Layer5_1_Dropout2 = layers.Dropout(self.drop_out[1])\n",
        "        self.Pred_Layer5_2_Regul_L1 = layers.ActivityRegularization(l1=0.1)\n",
        "        self.Pred_Layer5_2_Regul_L2 = layers.ActivityRegularization(l2=0.1)\n",
        "        self.Pred_Layer6_reshape1   = layers.Reshape([input_shape[1], input_shape[2], 1])\n",
        "        self.Pred_Layer7_conv3      = layers.Conv2D(filters = self.num_n_deep[2], kernel_size=self.kernel_size[2], padding=\"SAME\",  activation=\"relu\")\n",
        "        self.Pred_Layer8_conv4      = layers.Conv2D(filters = self.num_n_deep[3], kernel_size=self.kernel_size[3], padding=\"SAME\",  activation=\"relu\")\n",
        "        self.Pred_Layer9_reshape2   = layers.Reshape([input_shape[1], input_shape[2]])\n",
        "        super().build(input_shape)\n",
        "\n",
        "\n",
        "    def call(self, inputs, regul=0):\n",
        "        if regul == 1:\n",
        "            self.inputsA = self.Pred_Layer0_Noise(inputs)\n",
        "        if regul == 2:\n",
        "            self.inputsA = self.Pred_Layer0_Dropout1(inputs)\n",
        "        if regul == 3:\n",
        "            self.inputsA = inputs\n",
        "        if regul == 4:\n",
        "            self.inputsA = inputs\n",
        "        if regul == 0:\n",
        "            self.inputsA = inputs\n",
        "        self.L1  = self.Pred_Layer1_conv1(self.inputsA)\n",
        "        self.L2  = self.Pred_Layer2_conv2(self.L1)\n",
        "        self.L3  = self.Pred_Layer3_flatten(self.L2)\n",
        "        self.L4  = self.Pred_Layer4_Dense1(self.L3)\n",
        "        self.L5  = self.Pred_Layer5_Dense2(self.L4)\n",
        "        if regul == 2:\n",
        "            self.L5  = self.Pred_Layer5_1_Dropout2(self.L5)\n",
        "        if regul == 3:\n",
        "            self.L5  = self.Pred_Layer5_2_Regul_L1(self.L5)\n",
        "        if regul == 4:\n",
        "            self.L5  = self.Pred_Layer5_2_Regul_L2(self.L5)\n",
        "        self.L6  = self.Pred_Layer6_reshape1(self.L5)\n",
        "        self.L7  = self.Pred_Layer7_conv3(self.L6)\n",
        "        self.L8  = self.Pred_Layer8_conv4(self.L7)\n",
        "        self.L9  = self.Pred_Layer9_reshape2(self.L8)\n",
        "        return self.L9"
      ],
      "metadata": {
        "id": "4pxl8p19MJ-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (None, 28, 28, 1)\n",
        "\n",
        "Model1 = Auto_regul()\n",
        "Model1.build(input_shape)\n",
        "Model1.summary()"
      ],
      "metadata": {
        "id": "_Ng-9sQwOshH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento para Autoencoder Regularizados\n",
        "\n",
        "### Loss MSE\n",
        "\n",
        "Para el calculo del error o la función de costo se utliza Mean Squared Error. Se utlizo diferentes metodos de calculo de error como BinaryCrossentropy y el que presenta mejor resultado tanto como error como generalización fue MSE.\n",
        "\n",
        "\n",
        "$$\n",
        "MSE  = \\frac{1}{n}\\sum_{i=1}^{n}\\left ( y_i -  \\hat{y_i}\\right )^{2}\n",
        "$$"
      ],
      "metadata": {
        "id": "cwvBLdQJOvEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Autoencoder Training\n",
        "tf.keras.backend.clear_session()\n",
        "loss_object = tf.keras.losses.MeanSquaredError()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Define measures to track loss\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "test_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "\n",
        "# Training loop\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "\"\"\"Selección del tipo de regularizador:\n",
        "r = 0 --- Sin gegularizador\n",
        "r = 1 --- Ruido gausiano\n",
        "r = 2 --- Dropout Capa entrada y salida Encoder\n",
        "r = 3 --- Regulairzador L1\n",
        "r = 4 --- Regulairzador L2\n",
        "\"\"\"\n",
        "regularizador = 4\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, reg=0):\n",
        "    with tf.GradientTape() as tape:\n",
        "        encod = Model1(images, reg, training=True)\n",
        "        loss_enc = loss_object(images, encod)\n",
        "    gradients_rec = tape.gradient(loss_enc, Model1.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients_rec, Model1.trainable_variables))\n",
        "    train_loss(loss_enc)\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, reg=0):\n",
        "    encod = Model1(images, reg, training=False)\n",
        "    t_loss_enc = loss_object(images, encod)\n",
        "    test_loss(t_loss_enc)\n",
        "\n",
        "\n",
        "# Prepare the dataset for training\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_tr).shuffle(buffer_size=1024).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(x_ts).shuffle(buffer_size=128).batch(batch_size)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(x_vl).shuffle(buffer_size=128).batch(batch_size)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Reset the metrics at the start of each epoch\n",
        "    train_loss.reset_states()\n",
        "    test_loss.reset_states()\n",
        "\n",
        "    for images in train_dataset:\n",
        "        train_step(images, regularizador )\n",
        "\n",
        "    for ts_images in test_dataset:\n",
        "        test_step(ts_images, regularizador )\n",
        "\n",
        "    print(f'Epoch {epoch + 1}, '\n",
        "          f'Loss: {train_loss.result()}, '\n",
        "          f'Test Loss: {test_loss.result()}')\n",
        "    if (epoch+1)%0.1 == 0:\n",
        "      ts_reconstructed = Model1(ts_images, regularizador, training=False)\n",
        "      print(ts_reconstructed.shape)\n",
        "      plot_mnist_autoencoder(ts_images,ts_reconstructed)\n",
        "\n",
        "Model1.summary()"
      ],
      "metadata": {
        "id": "xOeTp8gxOxDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualización de la reconstrucción de 15 imagenes del dataset de validación"
      ],
      "metadata": {
        "id": "YjqhaDy1OzEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_pred = Model1(x_vl[:15])\n",
        "\n",
        "plot_mnist_autoencoder(x_vl[:15],x_pred)\n",
        "print(y_vl[:15])"
      ],
      "metadata": {
        "id": "_Ebzl4LSOzp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualización PCA de las capas del modelo\n",
        "\n",
        "Se genera una visualización por reducción de caracteristicas para poder identificar patrones y facilitar las modificaciones de los parametros entre capas. La reducción del espacio se PCA para la salida de cada capa del modelo y se colorean la imagen segun la clase."
      ],
      "metadata": {
        "id": "x9hQd-IlO2Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Model1(x_vl, regularizador)\n",
        "\n",
        "plot_car_PCA(Model1,y_vl)"
      ],
      "metadata": {
        "id": "YaTvX3fXO3v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoder Variacional VAE\n",
        "\n",
        "Los autoencoder variacionales busca reconstruir imagenes que permita en el espacio latente tener interpolación de datos de una clase a la otra y la reconstrucción sea mas suavizada y uniforme \"Regular\".\n",
        "\n",
        "Para Realizar esto definimos el espacio latente como la probabilidad de distribución de una función que describe la entrada.\n",
        "\n",
        "$$\n",
        " Z = P(z \\mid x)\n",
        "$$\n",
        "Por lo generar se utiliza la función de distribución de probabilidad Normal, esto le da continuidad al espacio latente.\n",
        "$$\n",
        "P(x)=\\frac{1}{\\sigma \\sqrt{2\\pi }}e^{-\\frac{(x-\\mu )^{2}}{2\\sigma^{2}}}\n",
        "$$\n",
        "\n",
        "Para generar la funcion de distribución de probabilidad del encoder para el espacio latente se generan 2 capas que son las media ($\\mu $) y desviación estandar log($\\sigma ^{2}$). Estas son las salidas del encoder para poder modelar la función de distribución de probabilidad que siga la normal.\n",
        "\n",
        "Para facilitar el aprendizaje el espacio latente Z se modela de la siguiente manera\n",
        "\n",
        "$$\n",
        "Z = e^{\\frac{log(\\sigma ^{2})}{2}}\\odot \\zeta +\\mu\n",
        "$$\n",
        "\n",
        "Nota: Bajo modelos probabilisticos se busca resolver problemas más complejos: trabajar con multiples salidas, modelar la estructura de los datos, etc."
      ],
      "metadata": {
        "id": "4BQFQkHcO6te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Auto_VAE(Model):\n",
        "    def __init__(self, num_n_deep= [64, 32, 64, 2, 64, 576], **kwargs):\n",
        "        super(Auto_VAE, self).__init__()\n",
        "        self.num_n_deep = num_n_deep\n",
        "        self.mean = None\n",
        "        self.log_var = None\n",
        "        self.L_n= 12\n",
        "        self.L1 = None\n",
        "        self.L2 = None\n",
        "        self.L3 = None\n",
        "        self.L4 = None\n",
        "        self.L5 = None\n",
        "        self.L6 = None\n",
        "        self.L7 = None\n",
        "        self.L8 = None\n",
        "        self.L9 = None\n",
        "        self.L10 = None\n",
        "        self.L11 = None\n",
        "        self.L12 = None\n",
        "\n",
        "    def build(self, input_shape, kernel_size=[3, 3, 3, 3]):\n",
        "        self.kernel_size = kernel_size\n",
        "        self.VAE_Layer0_Noise       = layers.GaussianNoise(0.2)\n",
        "        self.VAE_Layer1_conv1        = layers.Conv2D(filters = self.num_n_deep[0], kernel_size=self.kernel_size[0], strides=(2, 2), activation=\"relu\")\n",
        "        self.VAE_Layer2_conv2        = layers.Conv2D(filters = self.num_n_deep[1], kernel_size=self.kernel_size[1], strides=(2, 2),  activation=\"relu\")\n",
        "        self.VAE_Layer2_Flatten1     = layers.Flatten()\n",
        "        self.VAE_Layer3_Dense1       = layers.Dense(units=self.num_n_deep[2], activation='relu')\n",
        "        self.VAE_Layer4_Mean         = layers.Dense(units=self.num_n_deep[3])\n",
        "        self.VAE_Layer5_Log_var      = layers.Dense(units=self.num_n_deep[3])\n",
        "        self.VAE_Layer7_Dense2       = layers.Dense(units=self.num_n_deep[4], activation='relu')\n",
        "        self.VAE_Layer8_Dense3       = layers.Dense(units=self.num_n_deep[5], activation='relu')\n",
        "        self.VAE_Layer9_reshape1     = layers.Reshape([24, 24, 1])\n",
        "        self.VAE_Layer10_conv3       = layers.Conv2DTranspose(filters = self.num_n_deep[1], kernel_size=self.kernel_size[2],  activation=\"relu\")\n",
        "        self.VAE_Layer11_conv4       = layers.Conv2DTranspose(filters = 1, kernel_size=self.kernel_size[3],  activation=\"sigmoid\")\n",
        "        self.VAE_Layer12_reshape2    = layers.Reshape([input_shape[1], input_shape[2],1])\n",
        "        super().build(input_shape)\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs, gen=False):\n",
        "        def Ngaussian(Enc):\n",
        "            self.mean, self.log_var = Enc\n",
        "            return keras.backend.random_normal(tf.shape(self.log_var)) * keras.backend.exp(self.log_var / 2) + self.mean\n",
        "\n",
        "        if gen == False:\n",
        "            #self.L0  = self.VAE_Layer0_Noise(inputs)\n",
        "            self.L1  = self.VAE_Layer1_conv1(inputs)\n",
        "            self.L2  = self.VAE_Layer2_conv2(self.L1)\n",
        "            self.L2  = self.VAE_Layer2_Flatten1(self.L2)\n",
        "            self.L3  = self.VAE_Layer3_Dense1(self.L2)\n",
        "            self.L4  = self.VAE_Layer4_Mean(self.L3)\n",
        "            self.L5  = self.VAE_Layer5_Log_var(self.L3)\n",
        "            self.L6   = Ngaussian((self.L4, self.L5))\n",
        "        if gen == True:\n",
        "            self.L6   = inputs\n",
        "        self.L7  = self.VAE_Layer7_Dense2(self.L6)\n",
        "        self.L8  = self.VAE_Layer8_Dense3(self.L7)\n",
        "        self.L9  = self.VAE_Layer9_reshape1(self.L8)\n",
        "        self.L10  = self.VAE_Layer10_conv3(self.L9)\n",
        "        self.L11  = self.VAE_Layer11_conv4(self.L10)\n",
        "        self.L12  = self.VAE_Layer12_reshape2(self.L11)\n",
        "        return self.L12"
      ],
      "metadata": {
        "id": "EppfiWZMO7Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (None, 28, 28, 1)\n",
        "\n",
        "Model2 = Auto_VAE()\n",
        "Model2.build(input_shape)\n",
        "Model2.summary()"
      ],
      "metadata": {
        "id": "wA7RiWOKPAMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Kullback-Leibler divergence KL\n",
        "El loss para VAE Se utiliza dos loss uno que es la diferencia de la reconstrucción por BinaryCrossEntropy y el Kullback–Leibler divergence el cual es un metodo matematico para calcular la distancia estadistica entre dos funciones de distribución de probabilidad. para nuestro caso como no tenemos la función de ditribución real para poder determinar la diferencie entre ellas asumimos que la funcion de ditribución debe ser una normal con media 0 y variación estandar de 1.\n",
        "$$\n",
        "BinaryCrossEntropy = \\frac{1}{N}\\sum_{i=1}^{N}\\left [ y_i*log(y_{pred})+(1-y_i)*log(1-y_{pred}) \\right ]\\\\ \\\\ \\\\\n",
        "$$\n",
        "\n",
        "$$\n",
        "KL[N(\\mu_{x},\\sigma_{x}),N(0,1)] = -0.5 * \\sum_{i=1}^{n}(1+log(Z_{\\sigma i}^{2})-Z_{\\mu i}^{2}-e^{log(Z_{\\sigma i}^{2})})\\\\ \\\\ \\\\\n",
        "\n",
        "$$\n",
        "$$\n",
        "loss=BinaryCrossEntropy+KL[N(\\mu_{x},\\sigma_{x}),N(0,1)]\\\\\n",
        "$$"
      ],
      "metadata": {
        "id": "8pDMiNQzPCGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "epochs=20\n",
        "batch_size=64\n",
        "# Define measures to track loss\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "test_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "\n",
        "# Prepare the dataset for training\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_tr).shuffle(buffer_size=1024).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(x_ts).shuffle(buffer_size=128).batch(batch_size)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(x_vl).shuffle(buffer_size=128).batch(batch_size)\n",
        "\n",
        "\n",
        "def compute_loss(model, x):\n",
        "  X=model(x)\n",
        "  mean= model.L4\n",
        "  logvar = model.L5\n",
        "  reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.binary_crossentropy(x, X),axis=(1, 2),))\n",
        "  kl_loss = -0.5 * (1 + logvar - tf.square(mean) - tf.exp(logvar))\n",
        "  kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "  total_loss = reconstruction_loss + kl_loss\n",
        "  return total_loss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step_VAE(model, x, optimizer):\n",
        "  \"\"\"Executes one training step and returns the loss.\n",
        "\n",
        "  This function computes the loss and gradients, and uses the latter to\n",
        "  update the model's parameters.\n",
        "  \"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(model, x)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "\n",
        "@tf.function\n",
        "def test_step_VAE(model, x):\n",
        "  loss_test = compute_loss(model, x)\n",
        "  test_loss(loss_test)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  for images in train_dataset:\n",
        "      train_step_VAE(Model2, images,  optimizer)\n",
        "  for ts_images in test_dataset:\n",
        "      test_step_VAE(Model2, ts_images)\n",
        "  print(f'Epoch {epoch + 1}, '\n",
        "        f'Loss: {train_loss.result()}, '\n",
        "        f'Test Loss: {test_loss.result()}')\n",
        "  #if (epoch+1)%0.1 == 0:\n",
        "    #ts_reconstructed = Model1(ts_images, training=False)\n",
        "    #print(ts_reconstructed.shape)\n",
        "    #plot_mnist_autoencoder(ts_images,ts_reconstructed)"
      ],
      "metadata": {
        "id": "3VgPWu3DPEfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_pred = Model2(x_vl[:15])\n",
        "\n",
        "plot_mnist_autoencoder(x_vl[:15],x_pred)\n",
        "print(y_vl[:15])"
      ],
      "metadata": {
        "id": "tXu50VcGPGtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model2(x_vl)\n",
        "\n",
        "plot_car_PCA(Model2,y_vl)"
      ],
      "metadata": {
        "id": "eZLITk2CPIah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numImgs = 30\n",
        "newrows,newcols=28,28\n",
        "lo, hi  = -2,2\n",
        "\n",
        "z1 = np.linspace(lo, hi, numImgs)\n",
        "z2 = np.linspace(lo, hi, numImgs)\n",
        "\n",
        "plt.figure(figsize=(15,15*newcols/newrows))\n",
        "canvas=np.zeros((newrows*numImgs,newcols*numImgs))\n",
        "for i in range(numImgs):\n",
        "    for j in range(numImgs):\n",
        "        z=np.array([z1[i], z2[j] ])\n",
        "        z=np.expand_dims(z, axis=0)\n",
        "        Im=Model2(z, gen=True).numpy()\n",
        "        canvas[newrows*i:newrows*(i+1), newcols*j:newcols*(j+1)] = Im.reshape((newrows,newcols))\n",
        "\n",
        "plt.imshow(canvas, 'gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gj70N-jvPKWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## GAN transformación inversa.\n",
        "Las GAN utilizan dos redes neuronales, una que se encarga de realizar la genereación de (imagen, texto, etc) y otra red que es entrenada para determinar si la imagen generada es real o fake, de esta manera se entrena el modelo generativo para identificar la CDF o función de densidad de probabilidad que asemeje a la generación de un dato al espacio de los datos de entrenamiento de forma indirecta, ya que no conocemos el CDF real de los datos. El entrenamiento se hace para que el generador engañe al discriminador y el discriminador detecte la imagen fake. Por tal motivo es el nombre adversarias ya que una se contrapone a la otra red y asi la competencia hace que se mejore la CDF de la red.\n",
        "\n",
        "\n",
        "La GAN es un modelo generativo se basa en la transformación inversa de una función de densidad de probabilidad, el objetivo es encontrar la función de densidad de probabilidad que se asemeje a la de nuestro conjunto de entrenamiento.\n",
        "\n",
        "$$\n",
        "CDF_X(x)=P(X\\leq x )\\\\\n",
        "$$\n",
        "\n",
        "$$\n",
        "CDF_U(u)=P(U\\leq u )= u \\\\\n",
        "$$\n",
        "\n",
        "$$\n",
        "    Y = CDF_X^{-1}(U)\n",
        "$$"
      ],
      "metadata": {
        "id": "GN223pdKPL1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Gen_GAN(Model):\n",
        "    \"\"\"\n",
        "    Clase Gen_GAN(Model):\n",
        "    Esta clase implementa un generador para una Red Generativa Adversarial (GAN), que toma una entrada de ruido\n",
        "    y genera una imagen.\n",
        "\n",
        "    Parámetros:\n",
        "    - num_n_deep (list): Lista que define el número de neuronas en las capas ocultas del generador.\n",
        "    - **kwargs: Argumentos adicionales que se pueden pasar a la clase Model.\n",
        "\n",
        "    Atributos:\n",
        "    - num_n_deep (list): Número de neuronas en las capas ocultas del generador.\n",
        "    - mean (None): Variable para almacenar la media de la distribución latente (no se utiliza en este código).\n",
        "    - log_var (None): Variable para almacenar el logaritmo de la varianza de la distribución latente (no se utiliza aquí).\n",
        "    - L_n (int): Número de capas en el generador.\n",
        "\n",
        "    Métodos:\n",
        "    - __init__: Constructor de la clase para inicializar los atributos.\n",
        "    - build: Método para construir la arquitectura del generador basado en la forma de entrada.\n",
        "    - call: Método que define la propagación hacia adelante en el generador.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, num_n_deep= [16*16*128, 64, 16], **kwargs):\n",
        "        super(Gen_GAN, self).__init__()\n",
        "        self.num_n_deep = num_n_deep\n",
        "        self.mean = None\n",
        "        self.log_var = None\n",
        "        self.L_n= 9\n",
        "        self.L1 = None\n",
        "        self.L2 = None\n",
        "        self.L3 = None\n",
        "        self.L4 = None\n",
        "        self.L5 = None\n",
        "        self.L6 = None\n",
        "        self.L7 = None\n",
        "        self.L8 = None\n",
        "        self.L9 = None\n",
        "\n",
        "    def build(self, input_shape, output_shape_p=[28, 28, 1]):\n",
        "        self.output_shape_p = output_shape_p\n",
        "        self.GAN_Layer1_Dense1    = layers.Dense(self.num_n_deep[0], use_bias=False, input_shape=(input_shape))\n",
        "        self.GAN_Layer2_Norm1     = layers.BatchNormalization()\n",
        "        self.GAN_Layer3_reshape1  = layers.Reshape([16,16,128])\n",
        "        self.GAN_Layer4_conv1     = layers.Conv2DTranspose(self.num_n_deep[1], kernel_size=5, activation=\"relu\")\n",
        "        self.GAN_Layer5_Norm2     = layers.BatchNormalization()\n",
        "        self.GAN_Layer6_conv2     = layers.Conv2DTranspose(self.num_n_deep[2], kernel_size=5, activation=\"relu\")\n",
        "        self.GAN_Layer7_Norm3     = layers.BatchNormalization()\n",
        "        self.GAN_Layer8_conv3     = layers.Conv2DTranspose(1, kernel_size=5, activation=\"tanh\")\n",
        "        self.GAN_Layer9_reshape2  = layers.Reshape(self.output_shape_p)\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        self.L1  = self.GAN_Layer1_Dense1(inputs)\n",
        "        self.L2  = self.GAN_Layer2_Norm1(self.L1)\n",
        "        self.L3  = self.GAN_Layer3_reshape1(self.L2)\n",
        "        self.L4  = self.GAN_Layer4_conv1(self.L3)\n",
        "        self.L5  = self.GAN_Layer5_Norm2(self.L4)\n",
        "        self.L6  = self.GAN_Layer6_conv2(self.L5)\n",
        "        self.L7  = self.GAN_Layer7_Norm3(self.L6)\n",
        "        self.L8  = self.GAN_Layer8_conv3(self.L7)\n",
        "        self.L9  = self.GAN_Layer9_reshape2(self.L8)\n",
        "        return self.L9"
      ],
      "metadata": {
        "id": "Pfvl94ArPOyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dis_GAN(Model):\n",
        "    \"\"\"\n",
        "    Clase Dis_GAN(Model):\n",
        "    Esta clase implementa un discriminador para una Red Generativa Adversarial (GAN), que evalúa la autenticidad\n",
        "    de una imagen generada por el generador.\n",
        "\n",
        "    Parámetros:\n",
        "    - num_n_deep (list): Lista que define el número de neuronas en las capas convolucionales del discriminador.\n",
        "    - **kwargs: Argumentos adicionales que se pueden pasar a la clase Model.\n",
        "\n",
        "    Atributos:\n",
        "    - num_n_deep (list): Número de neuronas en las capas convolucionales del discriminador.\n",
        "    - mean (None): Variable para almacenar la media de la distribución latente (no se utiliza en este código).\n",
        "    - log_var (None): Variable para almacenar el logaritmo de la varianza de la distribución latente (no se utiliza aquí).\n",
        "    - L_n (int): Número de capas en el discriminador.\n",
        "    - L1-L6 (None): Capas del discriminador que se inicializan como None en el constructor.\n",
        "\n",
        "    Métodos:\n",
        "    - __init__: Constructor de la clase para inicializar los atributos.\n",
        "    - build: Método para construir la arquitectura del discriminador basado en la forma de entrada.\n",
        "    - call: Método que define la propagación hacia adelante en el discriminador.\n",
        "\n",
        "    Uso:\n",
        "    # Crear una instancia de Dis_GAN\n",
        "    discriminador_gan = Dis_GAN(num_n_deep=[64, 128, 1])\n",
        "\n",
        "    # Construir el discriminador con la forma de entrada especificada\n",
        "    discriminador_gan.build(input_shape=(28, 28, 1))\n",
        "\n",
        "    # Realizar la propagación hacia adelante en el discriminador con una imagen de entrada\n",
        "    output_autenticidad = discriminador_gan(input_imagen_generada)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_n_deep= [64, 128, 1], **kwargs):\n",
        "        super(Dis_GAN, self).__init__()\n",
        "        self.num_n_deep = num_n_deep\n",
        "        self.mean = None\n",
        "        self.log_var = None\n",
        "        self.L_n= 6\n",
        "        self.L1 = None\n",
        "        self.L2 = None\n",
        "        self.L3 = None\n",
        "        self.L4 = None\n",
        "        self.L5 = None\n",
        "        self.L6 = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.GAN_Layer1_conv1       = layers.Conv2D(self.num_n_deep[0], kernel_size=5, strides=(2, 2), padding='same', activation=\"relu\", input_shape=(input_shape))\n",
        "        self.GAN_Layer2_Dropou1      = layers.Dropout(0.2)\n",
        "        self.GAN_Layer3_conv2       = layers.Conv2D(self.num_n_deep[1], kernel_size=5, strides=(2, 2), padding='same', activation=\"relu\")\n",
        "        self.GAN_Layer4_Dropou2      = layers.Dropout(0.2)\n",
        "        self.GAN_Layer5_flatten1    = layers.Flatten()\n",
        "        self.GAN_Layer6_Dense1      = layers.Dense(units=self.num_n_deep[2], activation='sigmoid')\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        self.L1  = self.GAN_Layer1_conv1(inputs)\n",
        "        self.L2  = self.GAN_Layer2_Dropou1(self.L1)\n",
        "        self.L3  = self.GAN_Layer3_conv2(self.L2)\n",
        "        self.L4  = self.GAN_Layer4_Dropou2(self.L3)\n",
        "        self.L5  = self.GAN_Layer5_flatten1 (self.L4)\n",
        "        self.L6  = self.GAN_Layer6_Dense1(self.L5)\n",
        "        return self.L6"
      ],
      "metadata": {
        "id": "lF6SCwgtPQby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (None, 100)\n",
        "\n",
        "Model3 = Gen_GAN()\n",
        "Model3.build(input_shape)\n",
        "Model3.summary()\n",
        "\n",
        "input_shape = (None, 28, 28, 1)\n",
        "\n",
        "Model4 = Dis_GAN()\n",
        "Model4.build(input_shape)\n",
        "Model4.summary()"
      ],
      "metadata": {
        "id": "OqTQT2nEPRZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "-jyeWWT9PS0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "wix9iqqSPTuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 16\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = Model3(noise, training=True)\n",
        "\n",
        "      real_output = Model4(images, training=True)\n",
        "      fake_output = Model4(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, Model3.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, Model4.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, Model3.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, Model4.trainable_variables))\n",
        "\n",
        "\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(Model3,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "\n",
        "    print ('epoch_')\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(Model3,epochs,seed)\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_tr*2-1).shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "SL1F9WmHPVYq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}