{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOgcUxtzdlGyFR6dBb3d0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosarroyave/AutoEnc-GAN/blob/main/AutoEnc%26GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8OO812CLoC2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot original images vs reconstructed images\n",
        "\n",
        "def plot_mnist_autoencoder(x, xpred, cmap='gray', vmin=0, vmax=1):\n",
        "    # Crear una figura y ejes para mostrar las imágenes originales y reconstruidas\n",
        "    fig, ax = plt.subplots(2, x.shape[0], figsize=(20, 5))\n",
        "\n",
        "    # Iterar sobre cada imagen en x y xpred para mostrarlas en subplots correspondientes\n",
        "    for i, class_ in enumerate(range(x.shape[0])):\n",
        "        # Mostrar la imagen original en la fila 0 del subplot\n",
        "        ax[0, i].imshow(x[i], cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "        ax[0, i].set_xticks([])\n",
        "        ax[0, i].set_yticks([])\n",
        "\n",
        "        # Mostrar la imagen reconstruida en la fila 1 del subplot\n",
        "        ax[1, i].imshow(xpred[i], cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "        ax[1, i].set_xticks([])\n",
        "        ax[1, i].set_yticks([])\n",
        "\n",
        "    # Mostrar la figura completa con todas las subplots\n",
        "    plt.show()\n",
        "\n",
        "# Ejemplo de uso de la función\n",
        "# Suponiendo que tienes imágenes en las variables x e xpred\n",
        "# plot_mnist_autoencoder(x, xpred)"
      ],
      "metadata": {
        "id": "V8vzIWygLr91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identificación de por PCA de los resultados de cada capa del modelo utilizado"
      ],
      "metadata": {
        "id": "E9niSahZLuBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_car_PCA(z, y, dim=2):\n",
        "    \"\"\"\n",
        "    Esta función realiza PCA (Análisis de Componentes Principales) en los datos de z y\n",
        "    luego visualiza las proyecciones en un gráfico de scatter para cada capa L en z.\n",
        "\n",
        "    Args:\n",
        "    - z: Objeto que contiene los datos a analizar (debe tener atributos L1, L2, ..., Ln).\n",
        "    - y: Etiquetas de clase para colorear los puntos en el gráfico de dispersión.\n",
        "    - dim: Número de dimensiones para la proyección PCA (por defecto es 2).\n",
        "\n",
        "    \"\"\"\n",
        "    num_L = z.L_n\n",
        "    fig, axes = plt.subplots(1, num_L, figsize=(10*num_L, 10))\n",
        "\n",
        "    for i in range(num_L):\n",
        "        # Obtener los datos de la capa L correspondiente\n",
        "        name_Z = f\"L{i+1}\"\n",
        "        L = getattr(z, name_Z).numpy()\n",
        "        shp = L.shape\n",
        "\n",
        "        # Realizar PCA dependiendo de la forma de los datos en la capa L\n",
        "        if len(shp) == 2:\n",
        "            zpca = PCA(n_components=dim).fit_transform(L.reshape((L.shape[0], L.shape[1])))\n",
        "        elif len(shp) == 3:\n",
        "            zpca = PCA(n_components=dim).fit_transform(L.reshape((L.shape[0], L.shape[1]*L.shape[2])))\n",
        "        elif len(shp) == 4:\n",
        "            zpca = PCA(n_components=dim).fit_transform(L.reshape((L.shape[0], L.shape[1]*L.shape[2]*L.shape[3])))\n",
        "\n",
        "        # Normalizar los datos de PCA entre 0 y 1\n",
        "        zpca = (zpca - zpca.min()) / (zpca.max() - zpca.min())\n",
        "\n",
        "        # Graficar la proyección PCA en un gráfico de scatter\n",
        "        axes[i].scatter(zpca[:, 0], zpca[:, 1], c=y, s=10, cmap=\"tab10\")\n",
        "        axes[i].set_title(f\"L{i+1}\")\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.5)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Ejemplo de uso de la función\n",
        "# plot_car_PCA(z, y, dim=2)"
      ],
      "metadata": {
        "id": "idRYTUnZLwNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataSet utlizado de keras fashion_mnist\n",
        "\n",
        "El dataset esta calsificado en las siguientes clases :  # T-shirt/top, \tTrouser, Pullover,\tDress, \tCoat, Sandal, Shirt, \tSneaker, Bag, Ankle boot"
      ],
      "metadata": {
        "id": "ocqh-8zHL0KJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "g7gdmb4aL1pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "División de los datos en Train, test y valid y se normalizan los datos de 0 a 1"
      ],
      "metadata": {
        "id": "GzFLpC8dL5FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ],
      "metadata": {
        "id": "6SOQC1FfL6Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "id": "VlxUq8T0L8AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0], cmap=\"gray\", vmin=0, vmax=1)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kAuuwPVML911"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se mezclan los datos para garantizar que el modelo no tenga overfitting por el orden de los datos en el entrenamiento."
      ],
      "metadata": {
        "id": "2o1IQzMSMByt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tamano = len(X_train)\n",
        "indice_mezcla = np.random.permutation(tamano)\n",
        "x_tr = X_train[indice_mezcla].reshape([tamano,28,28,1])\n",
        "tamano = len(X_valid)\n",
        "indice_mezcla = np.random.permutation(tamano)\n",
        "x_vl = X_valid[indice_mezcla].reshape([tamano,28,28,1])\n",
        "y_vl = y_valid[indice_mezcla]\n",
        "tamano = len(X_test)\n",
        "indice_mezcla = np.random.permutation(tamano)\n",
        "x_ts = X_test[indice_mezcla].reshape([tamano,28,28,1])"
      ],
      "metadata": {
        "id": "ICVUfSVbMCnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo Autoencoder con Regularizadores\n",
        "\n",
        "Se crea un modelo de autoencoder con una entrada de imagen (28,28) buscando reconstruir la imagen de entrada.\n",
        "\n",
        "Se utliza la siguiente arquitectura para el encoder y decoder.\n",
        "\n",
        "![Arquitectura](Imagenes/ArquitecturaAE.png)\n",
        "\n",
        "y se utliza la API de los modelos que permite keras para poder seleccionar que tipo de regularización se va a implementar.\n",
        "\n",
        "### Ruido gausiano:\n",
        "El primer regularizador es ruido gausiano en la capa de entrada, generando un grado de aleatoriedad a los datos de entrada y evitar el sobre entrenamiento.\n",
        "\n",
        "### Dropout:\n",
        "Se genera un apagado de las neuronas de forma aleatoria en la capa implementada lo que genera que algunas neuronas no sean las que se especialicen en el entrenamiento y se pueda distribuir el aprendizaje en todas las neuronas de la capa.\n",
        "\n",
        "###  Regularización L1 Lasso:\n",
        "Introduce un termino a la función de costo (L) añadiendo al valor el absoluto de los pesos de la capa, generando que los pesos sean pequeños y no se genere una neurona con mayor importancia que las otras neuronas de la capa.\n",
        "\n",
        "$$\n",
        "L_1(X,\\omega ) =  L(X,\\omega ) + \\lambda \\sum \\left |\\omega_i  \\right |\n",
        "$$\n",
        "\n",
        "###  Regularización L2 Ridge:\n",
        "\n",
        "Introduce un termino a la función de costo (L) añadiendo a su valor la suma de los cuadrados de los parametros ($\\omega$) y se introduce un parametro ($\\lambda$) para ajustar el peso de estos cuadrados de los pesos.\n",
        "\n",
        "$$\n",
        "L_2(X,\\omega ) =  L(X,\\omega ) + \\lambda \\sum \\omega_i^{2}\n",
        "$$"
      ],
      "metadata": {
        "id": "cfl-rV8OMHiF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4pxl8p19MJ-V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}